{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Real-Time, Personalized Movie Recommendations with Amazon Personalize\n",
    "\n",
    "# This notebook is intended to be run on a SageMaker notebook instance\n",
    "# Ensure the IAM role for the instance has these attached policies:\n",
    "#   - IAMFullAccess             -> IAM Policies & Roles will be created and passed to various AWS services\n",
    "#   - AmazonPersonalizeAccess   -> Allows this notebook to invoke API calls to Amazon Personalize\n",
    "#   - S3FullAccess              -> Allows this notebook to use S3 for staging datasets and storing model artifacts\n",
    "\n",
    "# Follow the steps in this AWS Lab for guidance:\n",
    "# https://aws.amazon.com/getting-started/hands-on/real-time-movie-recommendations-amazon-personalize/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Background and Setup\n",
    "import time\n",
    "from time import sleep\n",
    "import json\n",
    "from datetime import datetime\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset directory and load dataset\n",
    "data_dir = \"data\"\n",
    "!mkdir $data_dir\n",
    "!cd $data_dir && wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "!cd $data_dir && unzip ml-latest-small.zip\n",
    "dataset_dir = data_dir + \"/ml-latest-small/\"\n",
    "!ls $dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handy-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Download and Prepare Dataset\n",
    "\n",
    "# Load and preview dataset\n",
    "original_data = pd.read_csv(dataset_dir + '/ratings.csv')\n",
    "print(original_data.info())\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare different interaction data\n",
    "\n",
    "# Label interaction as \"watch\"\n",
    "watched_df = original_data.copy()\n",
    "watched_df = watched_df[watched_df['rating'] > 3]\n",
    "watched_df = watched_df[['userId', 'movieId', 'timestamp']]\n",
    "watched_df['EVENT_TYPE'] = 'watch'\n",
    "\n",
    "# Label interaction as \"clicked\"\n",
    "clicked_df = original_data.copy()\n",
    "clicked_df = clicked_df[clicked_df['rating'] > 1]\n",
    "clicked_df = clicked_df[['userId', 'movieId', 'timestamp']]\n",
    "clicked_df['EVENT_TYPE'] = 'click'\n",
    "\n",
    "# Combine interactions\n",
    "interactions_df = clicked_df.copy()\n",
    "interactions_df = interactions_df.append(watched_df)\n",
    "interactions_df.sort_values(\"timestamp\", axis = 0, ascending = True,\n",
    "                           inplace = True, na_position = 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for upload later\n",
    "interactions_df.rename(columns = {'userId':'USER_ID', 'movieId':'ITEM_ID',\n",
    "                                 'timestamp':'TIMESTAMP'}, inplace = True)\n",
    "interactions_filename = \"interactions.csv\"\n",
    "interactions_df.to_csv((data_dir + '/' + interactions_filename), \n",
    "                      index = False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SDK to Personalize\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')\n",
    "\n",
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"personalize-demo-movielens\"\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-cuisine",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Make sure dataset group is active before continuing\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"EVENT_TYPE\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        }\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"personalize-demo-movielens-interactions\",\n",
    "    schema = json.dumps(interactions_schema)\n",
    ")\n",
    "\n",
    "interaction_schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))\n",
    "\n",
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = \"personalize-demo-movielens-ints\",\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = interaction_schema_arn\n",
    ")\n",
    "\n",
    "interactions_dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 bucket to stage interactions dataset, and store model artifacts\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "s3 = boto3.client('s3')\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "bucket_name = account_id + \"-\" + region + \"-\" + \"personalizedemoml\"\n",
    "print(bucket_name)\n",
    "\n",
    "if region == \"us-east-1\":\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "else:\n",
    "    s3.create_bucket(\n",
    "        Bucket=bucket_name,\n",
    "        CreateBucketConfiguration={'LocationConstraint': region}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset to S3\n",
    "interactions_file_path = data_dir + \"/\" + interactions_filename\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(interactions_filename).upload_file(interactions_file_path)\n",
    "interactions_s3DataPath = \"s3://\" + bucket_name + \"/\" + interactions_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bucket policy for Personalize to read the content of the bucket\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:*Object\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket_name),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket_name)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket_name, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a role for Personalize to assume to execute certain tasks\n",
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeRolePOC\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Import the Dataset into Personalize\n",
    "\n",
    "# Create the import job\n",
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"personalize-demo-import1\",\n",
    "    datasetArn = interactions_dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}\".format(bucket_name, interactions_filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run the import job (10-15mins)\n",
    "max_time = time.time() + 6*60*60 # 6 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create and Evaluate a Solution\n",
    "\n",
    "# a. Recipe\n",
    "\n",
    "# aws-user-personalization selected for demo purposes\n",
    "recipe_arn = \"arn:aws:personalize:::recipe/aws-user-personalization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Parameters / Define Model\n",
    "# no custom solution or recipe params in this example\n",
    "\n",
    "create_solution_response = personalize.create_solution(\n",
    "    name = \"personalize-demo-soln-user-personalization\",\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = recipe_arn\n",
    ")\n",
    "\n",
    "solution_arn = create_solution_response['solutionArn']\n",
    "print(json.dumps(create_solution_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Solution Version / Train Model\n",
    "# each version is a trained model\n",
    "\n",
    "create_solution_version_response = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn\n",
    ")\n",
    "\n",
    "solution_version_arn = create_solution_version_response['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# train model (40-50mins)\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"SolutionVersion: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-improvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Evaluate Solution Version\n",
    "\n",
    "get_solution_metrics_response = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = solution_version_arn\n",
    ")\n",
    "\n",
    "print(json.dumps(get_solution_metrics_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a Campaign and get Recommendations for Users\n",
    "\n",
    "# create campaign\n",
    "create_campaign_response = personalize.create_campaign(\n",
    "    name = \"personalize-demo-camp\",\n",
    "    solutionVersionArn = solution_version_arn,\n",
    "    minProvisionedTPS = 1,\n",
    "    campaignConfig = {\n",
    "        \"itemExplorationConfig\": {\n",
    "        \"explorationWeight\": \"0.3\",\n",
    "        \"explorationItemAgeCutOff\": \"30\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "campaign_arn = create_campaign_response['campaignArn']\n",
    "print(json.dumps(create_campaign_response, indent=2))\n",
    "\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get real-time recommendations\n",
    "\n",
    "# Build a map to convert a movie id to the movie title\n",
    "movies = pd.read_csv(dataset_dir + '/movies.csv', usecols=[0,1])\n",
    "movies['movieId'] = movies['movieId'].astype(str)\n",
    "movie_map = dict(movies.values)\n",
    "\n",
    "# Getting a random user:\n",
    "user_id, item_id = interactions_df[['USER_ID', 'ITEM_ID']].sample().values[0]\n",
    "\n",
    "get_recommendations_response = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn,\n",
    "    userId = str(user_id),\n",
    ")\n",
    "\n",
    "# Update DF rendering\n",
    "pd.set_option('display.max_rows', 30)\n",
    "\n",
    "print(\"Recommendations for user: \", user_id)\n",
    "\n",
    "item_list = get_recommendations_response['itemList']\n",
    "\n",
    "recommendation_list = []\n",
    "\n",
    "for item in item_list:\n",
    "    title = movie_map[item['itemId']]\n",
    "    recommendation_list.append(title)\n",
    "    \n",
    "recommendations_df = pd.DataFrame(recommendation_list, columns = ['OriginalRecs'])\n",
    "recommendations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Delete the Amazon Personalize resources\n",
    "\n",
    "# Delete the campaign\n",
    "personalize.delete_campaign(campaignArn=campaign_arn)\n",
    "time.sleep(300)\n",
    "print(\"delete_campaign done\")\n",
    "# Delete the solution\n",
    "personalize.delete_solution(solutionArn=solution_arn)\n",
    "time.sleep(60)\n",
    "print(\"delete_solution done\")\n",
    "# Delete the interaction dataset\n",
    "personalize.delete_dataset(datasetArn=interactions_dataset_arn)\n",
    "time.sleep(60)\n",
    "print(\"delete_dataset done\")\n",
    "# Delete the schema\n",
    "personalize.delete_schema(schemaArn=interaction_schema_arn)\n",
    "time.sleep(60)\n",
    "print(\"delete_schema done\")\n",
    "# Delete the dataset group\n",
    "personalize.delete_dataset_group(datasetGroupArn = dataset_group_arn)\n",
    "time.sleep(60)\n",
    "print(\"delete_dataset_group done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete S3 Bucket and IAM Policies\n",
    "\n",
    "# Empty S3 Bucket\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(interactions_filename).delete()\n",
    "# IAM policies should also be removed\n",
    "iam = boto3.client(\"iam\")\n",
    "iam.detach_role_policy(PolicyArn=\"arn:aws:iam::aws:policy/AmazonS3FullAccess\", RoleName=role_name)\n",
    "iam.detach_role_policy(PolicyArn=\"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\",RoleName=role_name)\n",
    "iam.detach_role_policy(PolicyArn=\"arn:aws:iam::aws:policy/service-role/IAMFullAccess\",RoleName=role_name)\n",
    "iam.delete_role(RoleName=role_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-maldives",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}