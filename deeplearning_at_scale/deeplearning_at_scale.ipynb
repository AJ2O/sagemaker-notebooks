{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "0. Prerequisites\n",
    "\n",
    "Python 3\n",
    "TensorFlow 1.15\n",
    "'''\n",
    "\n",
    "# download the CIFAR-10 dataset, a collection of images with 10 target classes\n",
    "!pip install ipywidgets\n",
    "!wget https://raw.githubusercontent.com/awslabs/amazon-sagemaker-examples/master/advanced_functionality/tensorflow_bring_your_own/utils/generate_cifar10_tfrecords.py\n",
    "!python generate_cifar10_tfrecords.py --data-dir cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import time, os, sys\n",
    "import sagemaker, boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# connect to sagemaker client endpoint\n",
    "sess = boto3.Session()\n",
    "sm   = sess.client('sagemaker')\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "\n",
    "# stage the dataset in the regional S3 bucket\n",
    "datasets = sagemaker_session.upload_data(path='cifar10', key_prefix='datasets/cifar10-dataset')\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "1. Start a SageMaker Experiment\n",
    "\n",
    "A SageMaker Experiment is the collection of processing and training jobs\n",
    "related to the same machine learning project. SageMaker Experiments\n",
    "automatically tracks training runs for the project.\n",
    "'''\n",
    "\n",
    "# import the sagemaker experiments package\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "from smexperiments.trial_component import TrialComponent\n",
    "\n",
    "# define the experiment, and attach the current sagemaker client to it\n",
    "training_experiment = Experiment.create(\n",
    "    experiment_name = \"sagemaker-training-experiments\", \n",
    "    description     = \"Experiment to track cifar10 training trials\", \n",
    "    sagemaker_boto_client=sm)\n",
    "\n",
    "# it will appear on the left toolbar, under\n",
    "# \"Components and registries\" -> \"Experiments and trials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. Create the Trial and Training Script.\n",
    "\n",
    "These scripts will be used to train a classifier on the CIFAR-10 dataset.\n",
    "A Trial is an iteration of the end-to-end training job.\n",
    "A Trial can also track:\n",
    "    - pre-processing jobs\n",
    "    - post-processing jobs\n",
    "    - metadata\n",
    "    - datasets\n",
    "The training job is defined in ./training_script.py.\n",
    "\n",
    "A single SageMaker Experiment can contain multiple trials, allowing\n",
    "for tracking multiple training iterations over time in the left toolbar.\n",
    "'''\n",
    "\n",
    "# create trial associated with this experiment\n",
    "single_gpu_trial = Trial.create(\n",
    "    trial_name = 'sagemaker-single-gpu-training', \n",
    "    experiment_name = training_experiment.experiment_name,\n",
    "    sagemaker_boto_client = sm,\n",
    ")\n",
    "\n",
    "trial_comp_name = 'single-gpu-training-job'\n",
    "experiment_config = {\"ExperimentName\": training_experiment.experiment_name, \n",
    "   \"TrialName\": single_gpu_trial.trial_name,\n",
    "   \"TrialComponentDisplayName\": trial_comp_name}\n",
    "\n",
    "# it will appear on the left toolbar\n",
    "# double-click the experiment name, and its associated trials will be listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. Run the TensorFlow training job and visualize the results.\n",
    "\n",
    "The training job is defined in ./training_script.py.\n",
    "'''\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# specify training job hyperparameters\n",
    "hyperparams={'epochs'       : 30,\n",
    "             'learning-rate': 0.01,\n",
    "             'batch-size'   : 256,\n",
    "             'weight-decay' : 2e-4,\n",
    "             'momentum'     : 0.9,\n",
    "             'optimizer'    : 'adam'}\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "output_path = f's3://{bucket_name}/jobs'\n",
    "metric_definitions = [{'Name': 'val_acc', 'Regex': 'val_acc: ([0-9\\\\.]+)'}]\n",
    "\n",
    "# define the sagemaker resources and configurations for the training job\n",
    "tf_estimator = TensorFlow(entry_point          = 'training_script.py', \n",
    "                          output_path          = f'{output_path}/',\n",
    "                          code_location        = output_path,\n",
    "                          role                 = role,\n",
    "                          train_instance_count = 1,\n",
    "                          train_instance_type  = 'ml.g4dn.xlarge',\n",
    "                          framework_version    = '1.15.2', \n",
    "                          py_version           = 'py3',\n",
    "                          script_mode          = True,\n",
    "                          metric_definitions   = metric_definitions,\n",
    "                          sagemaker_session    = sagemaker_session,\n",
    "                          hyperparameters      = hyperparams)\n",
    "\n",
    "# initiate the training job by fitting the model to the data\n",
    "job_name=f'tensorflow-single-gpu-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "tf_estimator.fit({'training'  : datasets,\n",
    "                  'validation': datasets,\n",
    "                  'eval'      : datasets},\n",
    "                 job_name = job_name,\n",
    "                 experiment_config=experiment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy is about ~67%\n",
    "\n",
    "'''\n",
    "4. Automatically tune the model with SageMaker for better results.\n",
    "\n",
    "In this step, we run a SageMaker automatic model tuning job to find the best\n",
    "hyperparameters for the model. Instead of specifying exact hyperparameter\n",
    "values, we specify ranges (integer, continuous, categorical) and run training\n",
    "jobs for each set of values.\n",
    "'''\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    'epochs'        : IntegerParameter(5, 30),\n",
    "    'learning-rate' : ContinuousParameter(0.001, 0.1, scaling_type='Logarithmic'), \n",
    "    'batch-size'    : CategoricalParameter(['128', '256', '512']),\n",
    "    'momentum'      : ContinuousParameter(0.9, 0.99),\n",
    "    'optimizer'     : CategoricalParameter(['sgd', 'adam'])\n",
    "}\n",
    "\n",
    "objective_metric_name = 'val_acc'\n",
    "objective_type = 'Maximize'\n",
    "metric_definitions = [{'Name': 'val_acc', 'Regex': 'val_acc: ([0-9\\\\.]+)'}]\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point          = 'cifar10-training-sagemaker.py', \n",
    "                          output_path          = f'{output_path}/',\n",
    "                          code_location        = output_path,\n",
    "                          role                 = role,\n",
    "                          train_instance_count = 1, \n",
    "                          train_instance_type  = 'ml.g4dn.xlarge',\n",
    "                          framework_version    = '1.15', \n",
    "                          py_version           = 'py3',\n",
    "                          script_mode          = True,\n",
    "                          metric_definitions   = metric_definitions,\n",
    "                          sagemaker_session    = sagemaker_session)\n",
    "\n",
    "# the tuner is now what will be fitted to the data\n",
    "tuner = HyperparameterTuner(estimator             = tf_estimator,\n",
    "                            objective_metric_name = objective_metric_name,\n",
    "                            hyperparameter_ranges = hyperparameter_ranges,\n",
    "                            metric_definitions    = metric_definitions,\n",
    "                            max_jobs              = 16,\n",
    "                            max_parallel_jobs     = 8,\n",
    "                            objective_type        = objective_type)\n",
    "\n",
    "job_name=f'tf-hpo-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}'\n",
    "tuner.fit({'training'  : datasets,\n",
    "           'validation': datasets,\n",
    "           'eval'      : datasets},\n",
    "            job_name = job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best test accuracy is about ~80%\n",
    "\n",
    "'''\n",
    "5. Clean up resources.\n",
    "'''\n",
    "!aws s3 rm --recursive s3://sagemaker-REGION-ACCOUNTNUMBER/datasets/cifar10-dataset\n",
    "!aws s3 rm --recursive s3://sagemaker-REGION-ACCOUNTNUMBER/jobs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 1.15 Python 3.7 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/tensorflow-1.15-gpu-py37-cu110-ubuntu18.04-v8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}